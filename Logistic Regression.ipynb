{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.array([fun(xi) for xi in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    return (x**2)*math.sin(2*math.pi*x)+0.7\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class uniRandom:\n",
    "    \n",
    "    \n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.dataPoints = np.empty(shape = (100,2))\n",
    "        self.labels = np.empty(100)\n",
    "        self.classOneX = np.empty(shape = (0,0))\n",
    "        self.classOneY = np.empty(shape = (0,0))\n",
    "        self.classZeroX = np.empty(shape = (0,0))\n",
    "        self.classZeroY = np.empty(shape = (0,0))\n",
    "        self.num0 = 0\n",
    "        for i in range(100):\n",
    "            self.dataPoints[i] = np.array([np.random.uniform(0,1), np.random.uniform(0,1)])\n",
    "            if fun(self.dataPoints[i][0]) > fun(self.dataPoints[i][1]):\n",
    "                self.labels[i] = 0\n",
    "                self.num0 += 1\n",
    "            else:\n",
    "                self.labels[i] = 1\n",
    "                \n",
    "    def assignClasses(self):\n",
    "        self.classOneX = np.empty(shape = (self.size - self.num0,2))\n",
    "        self.classOneY = np.empty(shape = (self.size - self.num0,2))\n",
    "        self.classZeroX = np.empty(shape = (self.num0,2))\n",
    "        self.classZeroY = np.empty(shape = (self.num0,2))\n",
    "        \n",
    "        counter0 = 0\n",
    "        counter1 = 0\n",
    "        for i in range(self.size):\n",
    "            values = np.array([fun(self.dataPoints[i][0]), fun(self.dataPoints[i][1])])\n",
    "            if(self.labels[i] == 0):\n",
    "                self.classZeroX[counter0] = self.dataPoints[i]\n",
    "                #print(self.dataPoints[i])\n",
    "                self.classZeroY[counter0] = values\n",
    "                counter0 += 1\n",
    "            else:\n",
    "                #print(self.dataPoints[i])\n",
    "                self.classOneX[counter1] = self.dataPoints[i]\n",
    "                self.classOneY[counter1] = values\n",
    "                counter1 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = uniRandom(100)\n",
    "x.assignClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x224b24ca1c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdPUlEQVR4nO3dbYxcV3kH8P9/nQQYNSxVvEgo9s6E1qlw41aQVZp+aWlNK8dSYrWiKGECQYpYBRoqC75EWom8oPlQEI2FFLXdthGBHQgBqcVBRpHqBlEhnGajEBsHOVnM7GYJahaR7hcL4niffrgz9ux4Xu7MfTvn3P9PWnln9nr23NmZZ859znPOoZlBRET8N1V0A0REJB0K6CIigVBAFxEJhAK6iEggFNBFRAJxRVG/eOfOnVar1Yr69SIiXnruued+aWYz/X5WWECv1WpYXl4u6teLiHiJ5OqgnynlIiISCAV0EZFAKKCLiARCAV1EJBAK6CIigVBAFxEJhAK6iEggRgZ0ko+SfI3kjwf8nCS/RHKF5EmS70u/mSIiMkqcHvqXARwY8vNbAOxpf80D+MfkzQpYswnUasDUVPRvs1l0i0Sc0zzVRO1IDVMPTqF2pIbmKb1P4hgZ0M3s+wB+NeSQQwC+YpETAN5B8l1pNTAozSYwPw+srgJm0b/z88UGdX3AiGOap5qYf3Ieq5urMBhWN1cx/+S8gnoMaeTQrwXwStft9fZ90mthATh3bvt9585F9xfBxQ8YKb2F4ws4d377++Tc+XNYOF7Q+8QjaQR09rmv7752JOdJLpNc3tjYSOFXe2Ztbbz7s+baB0zglEaIZ22z//th0P1ySRoBfR3A7q7buwC82u9AM1s0szkzm5uZ6btYWNhmZ8e7P2uufcAETGmE+Gan+78fBt0vl6QR0I8C+Gi72uVmAJtm9osUHjc8jQZQqWy/r1KJ7i/CoA+SqSnl1FOmNEJ8jf0NVK7c/j6pXFlBY39B7xOPxClb/DqAHwL4PZLrJO8meQ/Je9qHHANwFsAKgH8B8MnMWuu7eh1YXASqVYCM/l1cjO4vQr8PGAC4cEE59ZQpjRBffV8di7cuojpdBUFUp6tYvHUR9X0FvU88QrO+6e7Mzc3NmdZDd0CzGeXM19aiXvmFC5cfU60CrVbuTQtJ7UgNq5uXL2Ndna6idbiVf4PEWySfM7O5fj/TTNGyq9ejYL21FX31o5x6YkojSB4U0OUS1wZtA6I0guShsC3oxEGNRpQz7y5lLHLQNjD1fXUFcMmUeuhyiWuDtiIyFgV02a47p95qKZiXkCZA+UspFxG5qDMBqlMz35kABUDpIg+ohy4iF2kClN8U0EXkIk2A8psCuohcpHVU/KaALiIXxZkApUFTdymgi4Qihc1KRk2A0qqRbtNaLiIh6GxW0jspLOV5BFqTpnhay0UkdDltVqJBU7cpoIuEIKfNSpIMmir3nr1yB3RtkCyhyGlhtUlXjVTuPR/lDejaIFnS4kLHIKfdsCZdNVITlvJR3kHRWi0K4r20mUPYujf0mJ2NAl6SQcOcBiNjtyXNc0vR1INTsD57xxPE1v0D1uGXvoYNipY3oE9NRT3zXuTgjR7Eb1kEX3UMYlF1THpU5dKPNnMonywqQXIajPSddmzKR3kDek45R3FIFsFXHYNYtGNTPsq7fG7nEtvRnKNkYHa2f3okSfDVLk+xacem7JW3hw5oM4eyyeKqTLs8iUPK20OX8snqqqxeVwAXJ5S7h15GLtRMF0lXZRIw9dDLpLdsrzOZClBgEwmAvz30svc0J5HTAk6SMb32ZQA/e+jqaU5GNdP+02tfhvBzpqhm501Gz5v/9DcsvfBmiqqnORlNpvKfXvsyhJ8BXbPzJqOaaf/pte+2gsc3YgV0kgdIniG5QvK+Pj+fJfk0yedJniR5MP2mdlFPc3Iq2/ObXvvucmFJbjMb+gVgB4CfAng3gKsAvABgb88xiwA+0f5+L4DWqMe98cYbLZGlJbNq1YyM/l1aSvZ4Ir7Qa99N1apZFMq3f1Wrqf4aAMs2IK7G6aHfBGDFzM6a2RsAHgdwqPdzAcDb299PA3g1yYdMLOppiivyvszWa99NDoxvxAno1wJ4pev2evu+bg8AuJPkOoBjAD7V74FIzpNcJrm8sbExQXNFHOPCZba4wYHxjTgBnX3u6611vAPAl81sF4CDAL5K8rLHNrNFM5szs7mZmZnxW+sbTQAJnyZrSYcD4xtxAvo6gN1dt3fh8pTK3QCeAAAz+yGAtwLYmUYDvaWeWzk4cJktjnCgiixOQH8WwB6S15G8CsDtAI72HLMGYD8AkHwPooBe7pyKem7l4MBltjik4PGNkQHdzN4EcC+ApwD8BMATZnaa5EMkb2sf9hkAHyf5AoCvA/hYezTWHXmnP9RzKwcHLrNFLhpU/pL1V+KyxXEsLZlVKttLiSqVbMu9ciphEgdkWUbYeWzAbMeOS68hlSqWFoaULfq5lsu4ilj/Iosd5qVc+r2GOvRaKq3w1nIZVxHpDwcGSMRz/cZhOjQeI32UI6AXNXClCSCSxKgOR0DjMc1TTdSO1DD14BRqR2ponlI12CTKEdA1cJUP1d2na1SHI5BKmuapJuafnMfq5ioMhtXNVcw/Oa+gPoFyBHSlP7Knuvv09euIdATUIVk4voBz57enls6dP4eF40opjascg6KSPW28kI1mM8qVr64CO3YAFy5Ez2mjEUyHZOrBKdhlk88Bgti6f6uAFrlt2KCon1vQiXtUd5+Nej2YwD3I7PQsVjcv7wzMToeRUspTOVIukj3NmJQJNfY3ULlye2qpcmUFjf1hpJTypIAu6dDAs0yovq+OxVsXUZ2ugiCq01Us3rqI+r6wr0yyoBy6pKeT711bi3rmAeV5RVxRvolFKp8rhuruSyVO7bjqy/MVXkAva/mcPsQkR3Fqx1Vfnr/wUi5lLJ/TujGSs9qRWt/KlOp0Fa3DrdjHyPjKlXIpY/mc1l6XnK1t9n8/dd8f5xhJl98BvV+aoYzlc2X8EJNCDaoR774/zjGSLn8D+qBc+cGD4ZTPxc2LF/khptx9KcWpHVd9eQEGLZSe9VfiDS6GbSCR5YYDeRlnU44iNvAo8veKE5ZOLln14arxAVr14aotnbz87x7nGBkPgtzgYmoqCiG9yKhsznfjDu4WUQNexgFokYKFOSgaeq583Lx4ETXgRefule4R2cbfgB76VHMfPrCKzt2Xcb6ByBD+BvTQ1zj34QOryDaqVFPkMv7m0MvAh7VRimpj6GMoIgMMy6EroIufNCArPZqnmlg4voC1zTXMTs+isb8R5IqNYQ6KSrn5kJKS3GjdmIgCuvgp9DEUGYv2JY1oCzrxVwm2Z5N4tG5MRD10EfGe1o2JKKC7TBNnRGLRujERBXRXaeKMSGzalzSigO4qTZyJx5erGF/a6bH6vjpah1vYun8LrcOt0gVzIGZAJ3mA5BmSKyTvG3DMh0i+SPI0ya+l28wSKnqdFB/4chWTUzu1f6eMnFhEcgeAlwD8BYB1AM8CuMPMXuw6Zg+AJwD8uZm9TvKdZvbasMfVxKIRNHFmNF+eoxza2anD7i7dq1xZKWXaIXRJJxbdBGDFzM6a2RsAHgdwqOeYjwN4xMxeB4BRwVxi8HHiTN5pBV+uYnJop+qwBYgX0K8F8ErX7fX2fd2uB3A9yR+QPEHyQL8HIjlPcpnk8sbGxmQtLgvfJs4Ukf7wYUVKIJd2qg5bgHgBnX3u683TXAFgD4D3A7gDwL+SfMdl/8ls0czmzGxuZmZm3LaWTxFrnE+qiEFcX65icmin6rAFiBfQ1wHs7rq9C8CrfY75tpmdN7OfATiDKMC7YVQqQBUIyRWR/vDlKiaHdvpWh60B3IwM2puu84Wo930WwHUArgLwAoDf7znmAIDH2t/vRJSiuWbY4ybeUzSuUfteal/MdAzb41Vy4cv+nUsnl6zSqBgewMWvSqPibHtdg6R7ipI8COAIgB0AHjWzBsmH2g98lCQBfLEd2C8AaJjZ48MeM7cql1EVBr5USriuk0PvTrtUKm72mKVQtSM1rG5e/p6rTlfROtzKv0GeSbx8rpkdM7Przex3zKzRvu+zZna0/b2Z2afNbK+Z7RsVzHM1KhXgS6WE63xJf6RBKbpENICbnfBnio6qMPClUsIHPg3iDjMsYPsymclhGsDNTvgBfVSFgS+VEpKPUQFbSzIk5tsArk/CD+ijUgFlShXIaKMCtlJ0iWkhrexoT1GRbqM2n9YguhRMe4pK9kIZKBw1pqIUnThMAV2SC2mgcFTAVoquEJqIFI9SLpJcaGmIZjPKma+tRT3zRkMBu0BaSXK7YSkXBXRJblTeWSQBTUTaTjl0yZZq+SVDmogUnwJ61kIZLBxGA4WSIU1Eik8BPUshDRYOo4FCyZAmIsWnHHqWQhssFClI81QTC8cXsLa5htnpWTT2N0o5IApoULQ4GiwUkZRpULQoaQwWliEHL85R3befFNCzlHSwsCw5eHFKp+57dXMVBsPq5irmn5xXUPeAAnqWkg4WamU/KcDC8YVtk3gA4Nz5c1g4rted6xTQs5ZkjXCt7CcFyLruW+mc7Cigu8yXCTvK8wcVpLKs+1Y6J1sK6C7zYcJOWnl+jz8UQgtSWdZ9K52TLQV0l/kwYSeNPL/ng7+hBaksN6DQNP5sBVOHrokHBUmj1t7zCVhTD07BcPlzQBBb92u+QTcttJVc8HXooV3yJpF7LjeNPL/ng79aayQ+TePPVhABPbRL3kkV8sGWRp7fl8HfARSk4tN+otkKIqArLxcp5IMtjTz/uB8Kjg2gKkiNp76vjtbhFrbu30LrcEvPU4qCyKErLxfxOpcbd5egzgBq90BspeLeYLFIRoLPoeuSN+J1LjfuBCzNnhUZKIiArkveiLcfbOOkUDwfQBXJUhApF7nEu/LNcVMonpc4iiQVfMqlCK5O9fZuwGncFIoPs2dlJFffP767ougG+KhTHtipKOmUBwJwP4C6ZtwUSqfXHmcAVZyk9092YvXQSR4geYbkCsn7hhz3QZJGsu/lQCgGlQfe9e93qacxrklq0JOsYCmF07yR7IwM6CR3AHgEwC0A9gK4g+TePsddDeDvADyTdiNdM6i+/YJdKO0M1YkphVI6mjeSnTg99JsArJjZWTN7A8DjAA71Oe5zAD4P4Ncpts9Jw8oA1dMYkw8LkAWoyBy21+W1josT0K8F8ErX7fX2fReRfC+A3Wb2nWEPRHKe5DLJ5Y2NjbEb64p+5YHd1NMYk1IouSp67aMiymvLMggbJ6Czz30Xax1JTgF4GMBnRj2QmS2a2ZyZzc3MzMRvpWM6de87uKPvz9XTEJcVncPOe95I0R9geYoT0NcB7O66vQvAq123rwZwA4DvkWwBuBnA0dAHRuv76njsrx7zcyKPbJOk9+Zjz8+FHHae5bVFf4DlKU5AfxbAHpLXkbwKwO0AjnZ+aGabZrbTzGpmVgNwAsBtZhb8rCHNUPUzoHVL0nvztedXthy2Cx9geRkZ0M3sTQD3AngKwE8APGFmp0k+RPK2rBvoOu8m8qTI14DWLUnvzdeen7dLREyoTB9gserQzeyYmV1vZr9jZo32fZ81s6N9jn2/K71z33uPrvM1oHVL0nvztedXtivLMn2ABTtTVLPR0jNofRhfA1q32enZvksvx+m9Jfm/Ravvq5fmfdA5T6/WOJpQsGu5jNN7VE9+sGFplRAuZZP03g7uOTjW/VKcsqRGgw3ocXuPIeSBszTsgzGES9kk6YdjLx8b636RrAUb0OP2HkPIA2dp2AdjCLnYJMsNh5BykrAEm0Nv7G9sy6ED/XuPelMONypP7HMuNuk4i885dAlTsD30uL3HEPLAaeodTzi456D3aZVBkl6dhZBykrCUfsei3l4aEL0pfUsdpGHQc3HXH96FYy8fC65CII1Ntb3bIUq8N2zHomBTLnGVqaRplEE91mMvH0PrcCv5L2g2ndqYIo2Uic8pJwlPsCmXcZSlpGmUTMcTOnuHrq4CZtG/8/PDN4TOmFImkoUiy6AV0OWiTMcTxt07NAchVOmIW4ougy59Dl0uyXQ8YWoq6pn3IqN10EUCUDtS65vG28Ed2LKtVFK6w3Lo6qHLRZn2WCfZO1TEM8O2p8yjx64euuSjk0PvTrtUKtpuToIyqIfeqzpdnbjQQD10SUezCdRqUfqkVhtvQFN7h0oJjNqesiOriYulL1uUmHp72J0qFSB+UK7XFcAlaL1l0FOcwgW7cNlxWU1cVA9d4nGwSkXERd1l0HlvU6mALvGsDbhEHHS/iOReGquUi8QzOxulWfrdLyID5TmbWD10iafRiKpSulUq0f0i4gQFdIlHVSoizlPKReJTlYqI09RDFxEJhAK6iEggFNBFRAKhgC7ioCLX1BZ/KaCLOCarNbX1IRE+BXQRxyTdvLqfojdekHwooIs4JoutALP4kBD3lCKg61JTfJLFVoCZ7hcrzogV0EkeIHmG5ArJ+/r8/NMkXyR5kuRxktX0mzoZXWqKb7LYvDrT/WLFGSMDOskdAB4BcAuAvQDuILm357DnAcyZ2R8A+BaAz6fd0EnpUlN8k8UKfVl8SIh74kz9vwnAipmdBQCSjwM4BODFzgFm9nTX8ScA3JlmI5PQpab4KO0V+no3Xkhjs+Kya55qOvd8xgno1wJ4pev2OoA/GnL83QC+m6RRaZqdnu27x58uNaVs8lzGNXSdVG7n6r+TygVQ6HMcJ4fOPvf13Vma5J0A5gB8YcDP50kuk1ze2NiI38oEdKkprtEgvf9cTeXGCejrAHZ33d4F4NXeg0h+AMACgNvM7Df9HsjMFs1szszmZmZmJmnv2PLeMaQUkmwWXXIapA+Dq6lcmvXtbF86gLwCwEsA9gP4OYBnAXzYzE53HfNeRIOhB8zs5Ti/eG5uzpaXlydttxSld7NoINroQmujx1I7UuubAqxOV9E63Mq/QQEoIpdd5N+R5HNmNtfvZyN76Gb2JoB7ATwF4CcAnjCz0yQfInlb+7AvAPgtAN8k+SOSR1Nqu7hGm0Un4mrPzldFXfG4msod2UPPinronpqaAvq9Zkhgayv/9nhGPfR0Ffl8FlXlkqiHLp7JOr89aFPoEm4WPcngpqs9O18VecVT31dH63ALW/dvoXW45cS4nAJ6SDr57dXVqBe9uhrdTjOoa7NoAJNf6muQPl2aAbudUi4hqdWiIN6rWgVarfR+T7MZ5czX1qKeeaPh9YDoJJfOSp24obceHIiueEL+kFTKpSzWBlxmDrp/UvV69AGxtRX9m3cwTzGtNGlP2+XBzTLVueuKZzsF9JCUIb8dN60UM+hPOkHE1Ut9X+rc0/zQcTGXXRQF9JCUIb8dp2xyjLGESXvarg5uujqDsZsvHzo+UkAPSb0eTfCpVqMywmo1vAk/cdJKY9TKT9rTdvVS3+VUUIcPHzq+irM4l/ikXg8rgPeane0/8NudVhpjLKGxv9F3UC1OT9vFxa58WIzOhw8dX6mHHoqyrK8SJ600xliCqz3tSbmaCurm6vhDEMyskK8bb7zRJCVLS2aVilmUMY6+KpXo/hAtLZlVq2Zk9G/veZbt+eixdHLJqg9XjQ/Qqg9XbemkW+e9dHLJKo2K4QFc/Ko0Ks6101UAlm1AXA02oLv+ok5Vtbo9eHW+qtWiW1acUUFfClWq92fKhgX0ICcWlW6ygdZXESmN0k0sKt0oehnqz0VkpCADevCj6L0DoAcPhl9/LoUo06zTEAQZ0IMeRe83aeaxx4C77gq7/lxypwlA/gkyoPtQujWxQZNmjh0rdn0VCU7pUpcBCDKgh1ZbvE1eC3BJ6QWfugxQsDNFXZzFl4o4MyVFUuDDrFPZLsgeetDSXoCrLDNMZWxBpy4DpYDum94FuK65Bnjb24CPfGT8gJzHDkfiLZdTl6q+GWDQjKOsvzT1PwVJp7iXcYZp4DNIyzADs+xLB6BsM0VLI+mWc2WbYdq5IumuEqpUginxLMsM6bJv/1e6maKlkbTiJa0Zpr7k4cdYJ91HZSkzVPXNYAroPksakNMYYPUpDx94yWdZAl3QEwcTUkD3WdKAnMYORz71egNf86YsgU7VN4MpoPssjYBcryebYepTrzfwPVfLEuhcrr4pmgZFJZmkA7N5azajq4e1tahn3mgEMSDa0TzVxMLxBaxtrmF2ehaN/Q0FusAMGxRVQJdkAq8cEXGNqlwkO2mkfUQkFQroklzSPLzHksxY1GzHYoT8vMcK6CQPkDxDcoXkfX1+/haS32j//BmStbQbKuKaJOuFa63xYoT+vI8M6CR3AHgEwC0A9gK4g+TensPuBvC6mf0ugIcB/H3aDRVxTZKJPGWZBOSa0J/3OD30mwCsmNlZM3sDwOMADvUccwjAY+3vvwVgP0mm10wR9ySZyFOWSUCuCf15jxPQrwXwStft9fZ9fY8xszcBbAK4pveBSM6TXCa5vLGxMVmLRRyRZCJPWSYBuSb05z1OQO/X0+6tdYxzDMxs0czmzGxuZmYmTvtEnJVkIk9ZJgG5JvTnPU5AXwewu+v2LgCvDjqG5BUApgH8Ko0GirgqyYxFzXYsRujP+8iJRe0A/RKA/QB+DuBZAB82s9Ndx/wtgH1mdg/J2wH8tZl9aNjjamKRiMj4hk0sGrmnqJm9SfJeAE8B2AHgUTM7TfIhRAutHwXwbwC+SnIFUc/89vSaLyIiccTaJNrMjgE41nPfZ7u+/zWAv0m3aSIiMg7NFBURCYQCuohIIBTQRUQCoYAuIhIIBXQRkUAooIuIBKKwHYtIbgDos3dZbDsB/DKl5vhC51wOZTvnsp0vkOycq2bWd+2UwgJ6UiSXB82WCpXOuRzKds5lO18gu3NWykVEJBAK6CIigfA5oC8W3YAC6JzLoWznXLbzBTI6Z29z6CIisp3PPXQREemigC4iEginAzrJAyTPkFwheV+fn7+F5DfaP3+GZC3/VqYrxjl/muSLJE+SPE6yWkQ70zTqnLuO+yBJI+l9iVuccyb5ofbf+jTJr+XdxrTFeG3Pknya5PPt1/fBItqZJpKPknyN5I8H/Jwkv9R+Tk6SfF+iX2hmTn4h2kzjpwDeDeAqAC8A2NtzzCcB/FP7+9sBfKPodudwzn8GoNL+/hNlOOf2cVcD+D6AEwDmim53Dn/nPQCeB/Db7dvvLLrdOZzzIoBPtL/fC6BVdLtTOO8/AfA+AD8e8PODAL6LaF/mmwE8k+T3udxDvwnAipmdNbM3ADwO4FDPMYcAPNb+/lsA9pPst2G1L0aes5k9bWbn2jdPINrj1Wdx/s4A8DkAnwfw6zwbl5E45/xxAI+Y2esAYGav5dzGtMU5ZwPw9vb307h872LvmNn3MXx/5UMAvmKREwDeQfJdk/4+lwP6tQBe6bq93r6v7zFm9iaATQDX5NK6bMQ55253I/p099nIcyb5XgC7zew7eTYsQ3H+ztcDuJ7kD0ieIHkgt9ZlI845PwDgTpLriHZI+1Q+TSvUuO/5oWJtQVeQfj3t3hrLOMf4JPb5kLwTwByAP820Rdkbes4kpwA8DOBjeTUoB3H+zlcgSru8H9FV2H+TvMHM/i/jtmUlzjnfAeDLZvZFkn+MaJ/iG8xsK/vmFSbVGOZyD30dwO6u27tw+SXYxWNIXoHoMm3Y5Y3r4pwzSH4AwAKA28zsNzm1LSujzvlqADcA+B7JFqI841HPB0bjvra/bWbnzexnAM4gCvC+inPOdwN4AgDM7IcA3opoEauQxXrPx+VyQH8WwB6S15G8CtGg59GeY44CuKv9/QcB/Je1Rxo8NfKc2+mHf0YUzH3PqwIjztnMNs1sp5nVzKyGaNzgNjNbLqa5qYjz2v4PRAPgILkTUQrmbK6tTFecc14DsB8ASL4HUUDfyLWV+TsK4KPtapebAWya2S8mfrSiR4FHjBAfBPASotHxhfZ9DyF6QwPRH/ybAFYA/A+Adxfd5hzO+T8B/C+AH7W/jhbd5qzPuefY78HzKpeYf2cC+AcALwI4BeD2otucwznvBfADRBUwPwLwl0W3OYVz/jqAXwA4j6g3fjeAewDc0/V3fqT9nJxK+trW1H8RkUC4nHIREZExKKCLiARCAV1EJBAK6CIigVBAFxEJhAK6iEggFNBFRALx/0pAbDPlGyG7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x.classZeroX[:,0], x.classZeroX[:,1], color = 'r')\n",
    "plt.scatter(x.classOneX[:,0], x.classOneX[:,1], color = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_for(x):\n",
    "    return np.array([sigmoid(xi) for xi in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-55-634089508d42>, line 71)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-55-634089508d42>\"\u001b[1;36m, line \u001b[1;32m71\u001b[0m\n\u001b[1;33m    pass\u001b[0m\n\u001b[1;37m        \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "class network:\n",
    "    \n",
    "    #inner clas\n",
    "    class layers:#form as the mesh between two layers\n",
    "    \n",
    "            def __init__(self, vec):\n",
    "                self.weights = np.random.rand(vec[0],vec[1]) * 0.01\n",
    "                self.bias = np.random.rand(vec[1])\n",
    "                \n",
    "    class neurons: #forms a set of nodes in our network\n",
    "    \n",
    "        def __init__(self, x):\n",
    "            self.neurons = np.zeros(x)\n",
    "    \n",
    "        def len(self):\n",
    "            return len(self.neurons)\n",
    "    \n",
    "        def update(self, x):\n",
    "            self.neurons = x\n",
    "        \n",
    "        def getArray(self):\n",
    "            return self.neurons\n",
    "        \n",
    "    \n",
    "    def __init__(self, vec):\n",
    "        self.layers = []\n",
    "        #made up of layers with neurons\n",
    "        for i in range(len(vec) - 1): #build up until the layer before the final layer\n",
    "            self.layers.append(layers([vec[i], vec[i+1]]))\n",
    "        \n",
    "        self.neuronSet = []\n",
    "        for i in range(len(vec)):\n",
    "            self.neuronSet.append(neurons(vec[i])) #add the neurons for that specific layer, do this for each layer.\n",
    "        \n",
    "        #need some way to determine error, so here we have 2 classes therefore want to consider error the 'distance' from predicting the right class\n",
    "        #hence make target class have 1 - sigmoidAtEndNeuron and the class that it must not be \n",
    "        # 0 - sigmoidAtEndNeuron\n",
    "        #sum these two together to get the error\n",
    "        def errorCalculate(self, targetIndex): #this will be low when network is certain and high when it is uncertain \n",
    "            \n",
    "            '''\n",
    "            Note with regard to this function, please note that from my current understanding what you want to do is just for one given input example you want to target\n",
    "            what the classes should be and this will give you the error for that specific case, however you should note that this error is mainly just used to allow \n",
    "            for the use of descent https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html \n",
    "            As another note these should be used in conjungtion with back propagation. I will attempt to discuss that there\n",
    "            '''\n",
    "            \n",
    "            indexEnd = len(self.neuronSet) - 1\n",
    "            totalError = 0\n",
    "            neurons = self.neuronSet[indexEnd].getArray()\n",
    "            for i in range(len(neurons)): #architecture note, depends on only having one possible class you want it to be in \n",
    "                if i == targetIndex:\n",
    "                    totalError = (1 - neurons[i])**2 + totalError #should be squared difference\n",
    "                else:\n",
    "                    totalError = neurons[i]**2 + totalError #since sigmoid cant be <0 and fact that we want classes we arent to be at 0 (so completely off)\n",
    "            \n",
    "            return totalError\n",
    "        \n",
    "        def forwardPropagate(self , outShape, data):\n",
    "            out = np.empty(shape = (outshape[0],outShape[1]))\n",
    "            size = len(data) #number of entries to go through\n",
    "            for i in range(size):\n",
    "                dataPoint = data[i]\n",
    "                for j in range(len(self.layers) - 1): #run over each layer except for the last one\n",
    "                    dataPoint = array_for(np.dot(dataPoint, self.layers[j].weights) + self.layers.bias[j])\n",
    "          \n",
    "            #could add some error calculation here\n",
    "            out[i:,] = dataPoint\n",
    "            \n",
    "        def backPropagateHidden(): #require gradient of steepest descent in a form\n",
    "            #start from the output and go back\n",
    "            pass\n",
    "        '''\n",
    "        With regards to influence, think about the weight and the functions that are used in the activation i.e say o represents our sigmoid \n",
    "        o(w0a0 + w1a1 + ... wnan + bk) so we have 3 choices of things to change and nudge in the right step, thse things had influence on our current node\n",
    "        so, the weights(represented with w), the previous neurons(a's) and finally our bias vector. Do not interact with the neurons as they are meant to be left,\n",
    "        so instead interact with the weights or bias (preferably the weights). Since the weights have influence. We dont just do this for the target neuron, say for example\n",
    "        class 0 or class 1 only, we do it for both of them (so in the case that the label was 1, we reduce the cost for the neuron representing label 1 i.e (1- guessedProb) **2\n",
    "        and then for label 0 we say (-guessedProb)**2 since it should have been minimised) we then find out the changes that should have been made to all the weights, say for example\n",
    "        w1 in the last layer, class 0 says it should increase by 0.18 and class 1 says it should decrease by 0.1 so we aggregate the changes they want,\n",
    "        0.18 - 0.1 gives us what it should have for w1 by their aggregate demands on the changes.\n",
    "        I recommend looking at 3Blue1Brown's video on this (forward propagation is contained in video 1, 2 explains cost w.r.t gradient of descent and 3 is backprop)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n",
      "(5,)\n",
      "10\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "x = network([10,5])\n",
    "print(x.layers[0].weights.shape) \n",
    "print(x.layers[0].bias.shape)\n",
    "print(x.neuronSet[0].len()) # in this simple network, index 0 is the input neurons\n",
    "print(x.neuronSet[1].len()) # in this simple network, index 1 is the output neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
